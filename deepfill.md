# DeepFill
## Generative Image Inpainting with Contextual Attention
[[paper]](https://arxiv.org/abs/1801.07892)
- Abstract
    - Deep learning을 기반으로 한 inpainting 기법들은 유의미한 결과들을 만들어냈다. 하지만 주변 영역들과 일치하지 않거나 blur 현상이 발생한다.
    - 전통적인 inpainting은 주변의 texture을 가지고 맞추는 기법인데, 이를 착안해 주변의 texture와 structure를 반영한 방식을 제안한다.
    - 임의의 위치에서 여러개의 빈공간을 prediction(inpainting) 할 수 있다.
- Improved Generative Inpainting Network
    - Coarse-to-fine network architecture
        - 흰 직사각형 hole(or missing pixels)이 random하게 여러개 있는 image(z; 256x256)와 그 hole에 해당하는 영역을 나타낸 binary mask(m)가 input pair가 되고, hole을 inpainting한 이미지가 output(x̃)이 된다.
        - Receptive field를 크게 하고 안정된 학습을 위해서 stage coarse-to-fine network architecture(dilated conv)를 제안했다.
            - 첫번째 network에서 coarse prediction하고, 두번째 network에서 refined results를 만들어낸다.
            - Coarse network에서는 reconstruction loss를, refinement network에서는 reconstruction loss와 GAN loss를 취한다.
            - Details
                - Parameter를 줄여 효율을 높임
                - CNN에서는 mirror padding을 사용하고 batch norm 제거
                - Activation function은 ReLU대신 ELU 사용
                - Clip the output filter values instead of using tanh or sigmoid functions(*)
    - Global and local Wasserstein GANs
        - WGAN의 gradient penalty term에서 mask 적용
        - x와 x̃을 sampling한 x̂
    - Spatially discounted reconstruction loss
        - Mask의 pixel과 mask 경계 밖의 가장 가까운 pixel 간 거리(l)에 따라 weight(γ^l)를 매긴다.(mask 경계 부분이 mask 안쪽보다 모호함이 적기 때문)
        - Pixel-wise L1 reconstruction loss
    - 다른 inpainting model보다 수렴이 빠르다.
- Image Inpainting with Contextual Attention
    - Contextual Attention
        - Distant spatial한 위치의 feature을 가져오기에는 local 성향인 CNN은 비 효율적이므로 attention mechanism을 사용한다.
        - Foreground(missing pixels)와 background(surroundings) feature를 각각 추출하고 attention score를 구한다.
        - Background feature를 deconv해서 foreground를 reconstruction한다. (*)
        - Foreground와 background가 일관성이 있기 때문에 attention map을 kernel 영역만큼 propagation한다. (*)
        - 메모리 효율성을 위해 1) filter에 stride를 사용한다. 2) foreground를 downscaling한다. (*)
    - Unified Inpainting Network
        - 두 개의 encoder에서 나오는 feature들을 concat해서 decoder에 넣어준다.
- Experiments
    - Dataset: Places2, CelebA faces,  CelebAHQ faces, DTD textures, ImageNet
    - Qualitive comparisons
    - Attention map이 주변 정보를 가져와 synthesis와 generation에 도움을 준다.
    - Quantitative comparisons
        - L1 loss, L2 loss, PSNR(Peak Signal-to-Noise Ratio), TV(Total Variation) loss
    - 2.9M parameters, Tensorflow v1.3, CUDNN v6.0, CUDA v8.0, hardware with CPU Intel(R) Xeon(R) CPU E5-2697 v3 (2.60GHz) and GPU GTX 1080 Ti
    - 0.2 seconds per frame on GPU and 1.5 seconds per frame on CPU for images of resolution 512 × 512 on average
- Ablation study
    - Contextual attention vs. spatial transformer network and appearance flow
    - Choice of the GAN loss for image inpainting
    - Essential reconstruction loss
    - Perceptual loss, style loss and total variation loss
    
## Free-Form Image Inpainting with Gated Convolution
[[paper]](https://arxiv.org/abs/1801.07892v2)
- Abstract
    - Free-form mask and guidance로 image를 inpainting하는 system이며 label이 필요없다.
    - Gated convolution은 vanilla convolution과 비교하여 학습이 가능한 feature selection mechanism이다.
    - SN-PatchGAN으로 빠르고 안정된 학습이 가능하다.
- Approach
    - Gated Convolution
        - Vanilla convolution
            - 모든 pixel이 input으로 들어갈 경우에 사용(ex. image classification, object detection...)
            - Inpainting task의 경우 input이 valid, invalid로 되어있기 때문에 mask 영역에 대한 반영이 어려움
        - Partial convolution
            - Irregular mask에 대한 inpainting 성능을 향상시켰다.
            - Remaining issues
                - Spatial한 위치들이 valid, invalid한지 분류하는 것이 heuristic하다.
                - 추가적인 user input에 적합하지 않다.
                - Partial convolution을 위해 invalid pixel의 경우 layer에서 사라지고 valid pixel의 경우 1로 천천히 전환한다.
                - 각 레이어의 모든 채널들이 같은 mask를 공유해서 flexibility가 떨어진다.
            - Un-learnable single-channel feature hard-gating
        - Gated convolution
            - 각 spatial한 위치와 채널의 feature를 선택하는 것을 배운다.
            - O_y,x = φ(Feature_y,x) ⊙ σ(Gating_y,x)
    - Spectral-Normalized Markovian Discriminator (SN-PatchGAN)
        - 기존의 inpainting network(local GAN)의 경우에는 single rectangular hole을 채우는 방식
        - 본 논문에서는 여러개의 hole을 채우는 free-form image inpainting을 다루었다.
        - Markovian patches
        - GAN 학습의 안정성을 위해 spactral normalization 적용
    - Inpainting Network Architecture
        - Coarse and refinement networks; simple encoder-decoder network
        - Non-narrow mask의 경우에 Unet의 skip connection 효과가 없었다.
        - Gated convolution의 parameter가 추가로 들어가므로 효율성을 위해 모델을 줄였으나 성능의 하락은 보이지 않았다.
        - Fully convolutional하고 inference할때 다른 resolution도 지원이 된다.
    - Free-Form Mask Generation
        - Free-form mask를 자동으로 생성하는 알고리즘
        - 사용자가 지운 것처럼 하기 위해 임의의 점을 찍고 random angle과 random length로 선을 그린다.
    - Extension to User-Guided Image Inpainting
        - User-guided system; mask로 hole을 만들고 sketch로 inpainting의 guidance를 세운다.
        - Sketch generation; face의 경우에는 landmark, natural image의 경우에는 HED edge detector를 사용했다. 
        - 5-channel input(R,G,B color channels, mask channel and sketch channel)
- Results
    
